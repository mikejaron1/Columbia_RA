{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAlso just as a preliminary note, we are going to want to get the data on SIC codes and sales. \\nThen we want to compute do state x year x industry herfindahl indexes.\\n\\nProb start running code on text lab using jupyter qtconsole\\nfind which years are wrong then see how wrong they are\\ncreate master list of all companies... is the name the same? the dunns # uniques? etc.\\nfind some fuzzy name matching and address to compustat data\\n-- maybe find more extensive codebook\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Also just as a preliminary note, we are going to want to get the data on SIC codes and sales. \n",
    "Then we want to compute do state x year x industry herfindahl indexes.\n",
    "\n",
    "Prob start running code on text lab using jupyter qtconsole\n",
    "find which years are wrong then see how wrong they are\n",
    "create master list of all companies... is the name the same? the dunns # uniques? etc.\n",
    "find some fuzzy name matching and address to compustat data\n",
    "-- maybe find more extensive codebook\n",
    "\n",
    "\n",
    "12/6\n",
    "-check if this is firm level or not, ie. all walmarts or HQ\n",
    "-- can look at dunns # vs dunns parent #\n",
    "-find out which variables are permanent across years\n",
    "\n",
    "-email dunns and bradsheet about broken files\n",
    "-- tell them I have access through data through princeton libraries, and can they help me out with broken files\n",
    "-could also comment economic library at princeton, todd hines http://library.princeton.edu/econlib/contact-us\n",
    "and cc elliot\n",
    "\n",
    "-look at sales index\n",
    "\n",
    "\n",
    "files (ideally we want by firm)\n",
    "-id, parent  (if parent exists)\n",
    "-id, year, sales\n",
    "-id, sic\n",
    "-id, year, employment total?\n",
    "-id, business name, city, \n",
    "\n",
    "Prob start with this and look into adding data to the textlab postgres\n",
    "- in python psycopg2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   START  END  LENGTH Unnamed: 3 FIELD DESCRIPTION Unnamed: 5\n",
      "0      1    9       9       DUNS      DUN'S NUMBER        NaN\n",
      "1     10   39      30      DCOMP     BUSINESS NAME        NaN\n",
      "2     40   69      30     DTRADE  SECONDARY NAME -        NaN\n",
      "3     70   94      25    DSTREET    STREET ADDRESS        NaN\n",
      "4     95  114      20      DCITY              CITY        NaN\n"
     ]
    }
   ],
   "source": [
    "# directory = '/Users/mjaron/Desktop/RA/'\n",
    "\n",
    "# text_layot = pd.read_csv(directory+'HISTORICAL Layout 560.csv')\n",
    "text_layot = pd.read_excel('HISTORICAL Layout 560.xls', skiprows=1)\n",
    "print text_layot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "### get all bad years\n",
    "broken_files_df = pd.read_csv('broken_files_main.csv')\n",
    "# print broken_files_df.head()\n",
    "broken_files_list = list(broken_files_df['broken_file_years'])\n",
    "print type(broken_files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGNTFIS3.EKD3YY1Z.DMI.1969.TXT\n"
     ]
    }
   ],
   "source": [
    "for file_name in os.listdir(os.getcwd()):\n",
    "    if '.TXT' in file_name and '1969' in file_name:  ## to select a specific one\n",
    "#     if '.TXT' in file_name: ## any one\n",
    "        print file_name\n",
    "        file1 = open(file_name)\n",
    "#         print file1\n",
    "#         file1 = file1.readlines()\n",
    "#         print len(file1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS NAME\n",
      "SALES VOLUME\n",
      "GOVERNMENT DEFINED SIC CODE\n"
     ]
    }
   ],
   "source": [
    "print text_layot['FIELD DESCRIPTION'][1]\n",
    "print text_layot['FIELD DESCRIPTION'][23]\n",
    "print text_layot['FIELD DESCRIPTION'][48]\n",
    "\n",
    "# with open('company_names.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(['company_name', 'year', 'sic', 'sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_files_and_detect_bad_files(file1, year):\n",
    "    new_dict = {}\n",
    "    for count, i in enumerate(file1):\n",
    "#         print count, len(i)\n",
    "        if count >= 1000:\n",
    "            break\n",
    "        print year\n",
    "        if int(year) not in broken_files_list:  \n",
    "            print i[0:9], 'dunns #'\n",
    "            print i[333:342], 'dunn parent #'\n",
    "            company_name = i[text_layot['START'][1]-1:text_layot['END'][1]]\n",
    "            print company_name\n",
    "\n",
    "            sales = i[text_layot['START'][23]-1:text_layot['END'][23]]\n",
    "            sales = int(sales)\n",
    "            print sales\n",
    "\n",
    "            sic = i[text_layot['START'][48]-1:text_layot['END'][48]]\n",
    "            print sic\n",
    "        \n",
    "        else:\n",
    "            print i\n",
    "            company_name = i[22:52]\n",
    "            print company_name\n",
    "\n",
    "            sales = i[:]\n",
    "            sales = int(sales)\n",
    "            print sales\n",
    "\n",
    "            sic = i[200:204]\n",
    "            print sic\n",
    "            break\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        with open('company_names.csv', 'a') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([company_name, year, sic, sales])\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #         r = re.compile(\"([0-9]+)\")\n",
    "#         m = r.match(name)\n",
    "#         try:\n",
    "#             test = m.group(1)\n",
    "#             company_name = name[len(test)+1:]\n",
    "#             print company_name\n",
    "#         except:\n",
    "#             company_name = name\n",
    "#             print company_name\n",
    "            \n",
    "        \n",
    "        \n",
    "#         for count, field in enumerate(text_layot['FIELD DESCRIPTION']):\n",
    "#             temp = i[text_layot['START'][count]-1:text_layot['END'][count]]\n",
    "            \n",
    "#             ## set this up to try to decipher which files are not in line with the excel sheet\n",
    "#             ## business name is the second field and should just be characters\n",
    "#             ## it seems the corrupt files have longer dun #'s that run into the name\n",
    "#             ## I am just checking the first line b/c all of the lines should be same\n",
    "#             if field == \"BUSINESS NAME\":\n",
    "#                 r = re.compile(\"([0-9]+)\")\n",
    "#                 m = r.match(temp)\n",
    "#                 try:\n",
    "#                     test = m.group(1)\n",
    "#                     new_dict[field] = temp[len(test)+1:]\n",
    "#                     company_name = temp[len(test)+1:]\n",
    "#                     broken_file = file_name\n",
    "#                 except:\n",
    "#                     new_dict[field] = temp\n",
    "#                     company_name = temp\n",
    "#                     broken_file = 'na'\n",
    "                \n",
    "#                 ## stop looping through all of the variables and stop at business name\n",
    "#                 break\n",
    "#             if field == \"GOVERNMENT DEFINED SIC CODE\":\n",
    "                \n",
    "#             if field == \"SALES VOLUME\":\n",
    "                \n",
    "                \n",
    "                \n",
    "#             else:\n",
    "#                 new_dict[field] = temp\n",
    "\n",
    "        \n",
    "            \n",
    "#     return new_dict, broken_file\n",
    "\n",
    "# print file_name\n",
    "# clean_files_and_detect_bad_files(file1, year=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGNTFIS3.D6DV9BCL.DMI.1988.TXT\n",
      "1988\n",
      "1988\n",
      "MGNTFIS3.EKD3YY1Z.DMI.1969.TXT\n",
      "1969\n",
      "1969\n",
      "MGNTFIS3.ITNFJ9UX.DMI.2015.TXT\n",
      "2015\n",
      "2015\n",
      "MGNTFIS3.ST61JZ8P.DMI.2014.TXT\n",
      "2014\n",
      "2014\n",
      "MGNTFIS3.VTPKYNFB.DMI.1970.TXT\n",
      "1970\n",
      "1970\n",
      "MGNTFIS3.ZXU1P5L5.DMI.1989.TXT\n",
      "1989\n",
      "1989\n"
     ]
    }
   ],
   "source": [
    "with open('company_names.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['company_name', 'year', 'sic','sales'])\n",
    "    \n",
    "# broken_files = []\n",
    "master_dict = {}\n",
    "for file_name in os.listdir(os.getcwd()):\n",
    "    if '.TXT' in file_name:\n",
    "#     if '.TXT' in file_name and ('2015' in file_name or '2014' in file_name):\n",
    "        print file_name\n",
    "#         year = file_name[file_name.find('DMI.')+4:file_name.find('.TXT')]\n",
    "        print file_name[22:26]\n",
    "        print year\n",
    "#         file1 = open(file_name)\n",
    "#         file1 = file1.readlines()\n",
    "#         new_dict, broken_file = clean_files_and_detect_bad_files(file1, year)\n",
    "#         clean_files_and_detect_bad_files(file1, year)\n",
    "\n",
    "#         if broken_file != 'na':\n",
    "#             broken_files.append(broken_file)\n",
    "# #         master_dict[year] = new_dict\n",
    "#         df = pd.DataFrame({'broken_files': broken_files})\n",
    "#         df.to_csv('broken_files.csv', index = False) \n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1972'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-99704938d964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmaster_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mmaster_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1972'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mbroken_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1972'"
     ]
    }
   ],
   "source": [
    "print master_dict.keys()\n",
    "print master_dict['1972']\n",
    "print broken_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### get master list of business names\n",
    "duns_numb = []\n",
    "name = []\n",
    "for i in master_dict.keys():\n",
    "    duns_numb.append(master_dict[i][\"DUN'S NUMBER\"])\n",
    "    name.append(master_dict[i][\"BUSINESS NAME\"])\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "df['duns_number'] = duns_numb\n",
    "df['name'] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0234947\n"
     ]
    }
   ],
   "source": [
    "a = 2000.\n",
    "b = .0001\n",
    "a1 = 560469894.\n",
    "c = a1*b\n",
    "d = c/a\n",
    "print d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello 10\n"
     ]
    }
   ],
   "source": [
    "print \"hello %i\" %10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
